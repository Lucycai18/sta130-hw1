{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2dbe148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "row_n           0\n",
       "id              1\n",
       "name            0\n",
       "gender          0\n",
       "species         0\n",
       "birthday        0\n",
       "personality     0\n",
       "song           11\n",
       "phrase          0\n",
       "full_id         0\n",
       "url             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q1\n",
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "df = pd.read_csv(url)\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15b17eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 391\n",
      "Number of columns: 11\n"
     ]
    }
   ],
   "source": [
    "# Q2\n",
    "#(1)\n",
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Determine the number of rows and columns\n",
    "rows, columns = df.shape\n",
    "\n",
    "print(f\"Number of rows: {rows}\")\n",
    "print(f\"Number of columns: {columns}\")\n",
    "\n",
    "#(2)\n",
    "Definition:observations mean that the individual data points or cases in a dataset.\n",
    "Definition:variables mean that the different characteristics or measurements are recoreded of those observations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "967d8744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            row_n\n",
      "count  391.000000\n",
      "mean   239.902813\n",
      "std    140.702672\n",
      "min      2.000000\n",
      "25%    117.500000\n",
      "50%    240.000000\n",
      "75%    363.500000\n",
      "max    483.000000\n"
     ]
    }
   ],
   "source": [
    "#Q3\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Summary statistics for numerical columns\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6582462e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "species\n",
      "cat          23\n",
      "rabbit       20\n",
      "frog         18\n",
      "squirrel     18\n",
      "duck         17\n",
      "dog          16\n",
      "cub          16\n",
      "pig          15\n",
      "bear         15\n",
      "mouse        15\n",
      "horse        15\n",
      "bird         13\n",
      "penguin      13\n",
      "sheep        13\n",
      "elephant     11\n",
      "wolf         11\n",
      "ostrich      10\n",
      "deer         10\n",
      "eagle         9\n",
      "gorilla       9\n",
      "chicken       9\n",
      "koala         9\n",
      "goat          8\n",
      "hamster       8\n",
      "kangaroo      8\n",
      "monkey        8\n",
      "anteater      7\n",
      "hippo         7\n",
      "tiger         7\n",
      "alligator     7\n",
      "lion          7\n",
      "bull          6\n",
      "rhino         6\n",
      "cow           4\n",
      "octopus       3\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Q3\n",
    "# Count occurrences of each unique value in the 'species' column\n",
    "print(df['species'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74754c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataset: (391, 11)\n",
      "Summary statistics:\n",
      "            row_n\n",
      "count  391.000000\n",
      "mean   239.902813\n",
      "std    140.702672\n",
      "min      2.000000\n",
      "25%    117.500000\n",
      "50%    240.000000\n",
      "75%    363.500000\n",
      "max    483.000000\n",
      "Missing values in each column:\n",
      "row_n           0\n",
      "id              1\n",
      "name            0\n",
      "gender          0\n",
      "species         0\n",
      "birthday        0\n",
      "personality     0\n",
      "song           11\n",
      "phrase          0\n",
      "full_id         0\n",
      "url             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Q4\n",
    "#a)Non-numeric Variables:the number of columns reported by df.describe() can be smaller than the total number of columns in df.shape if my dataset contains non-numeric columns (such as strings or categorical variables). df.describe() will not include those non-numeric columns unless you explicitly include them.\n",
    "#b)Missing Values in Numeric Variables:The “count” column in df.describe() reflects the number of non-missing values in each column. If a numeric column has missing (NaN) values, df.describe() will report a lower “count” for that column compared to the total number of rows in df.shape.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Get the shape of the dataframe\n",
    "print(\"Shape of the dataset:\", df.shape)\n",
    "\n",
    "# Get the summary statistics of the dataframe\n",
    "print(\"Summary statistics:\")\n",
    "print(df.describe())\n",
    "\n",
    "# Checking for missing values in numeric columns\n",
    "print(\"Missing values in each column:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "#The discrepancy between df.shape and df.describe() arises because:\n",
    "#Non-numeric columns are excluded by default in df.describe().\n",
    "#Missing values reduce the “count” reported for each column in df.describe(), as it only counts non-null values.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab865b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q5\n",
    "#An attribute is a static piece of information about an object, like stored data that I can access directly without performing any operation. For example, df.shape simply tells you the size of the DataFrame.\n",
    "#In contrast, a method is an action that the object can perform, requiring me to call it with parentheses, like df.describe(), which processes the data to return summary statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b0963e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q6\n",
    "#Count:The number of non-missing (non-NaN) observations in the column.It represents how many values are present, excluding any missing data.\n",
    "#Mean:The average of the values in the column.It is calculated by summing all the non-missing values and dividing by the count of those values.\n",
    "#std:A measure of the dispersion or spread of the values in the column.It quantifies how much the values deviate from the mean.A larger standard deviation indicates more variability in the data.\n",
    "#min:The smallest value in the column.It represents the lower bound of the data.\n",
    "#25%:Also known as the first quartile (Q1).It is the value below which 25% of the data fall.It provides a measure of where the lower quarter of the data is located.\n",
    "#50%:Also known as the median.It is the middle value of the data, meaning 50% of the values are less than or equal to this value.Unlike the mean, the median is not affected by extreme values (outliers).\n",
    "#75%:Also known as the third quartile (Q3).It is the value below which 75% of the data fall.It shows where the upper quarter of the data starts.\n",
    "#max:The largest value in the column.It represents the upper bound of the data.\n",
    "\n",
    "#Summary of Percentiles (25%, 50%, 75%):\n",
    "\n",
    "#These are points that divide the data into quarters:\n",
    "\n",
    "#25% (Q1): Lower quartile, where the bottom 25% of the data lie.\n",
    "#50% (Q2/Median): Middle of the dataset.\n",
    "#75% (Q3): Upper quartile, where 75% of the data lie below this point."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da8dbb7",
   "metadata": {},
   "source": [
    "Here is a summary of our exchanges that you can submit as a record of our interactions for your homework assignment:\n",
    "\n",
    "Summary of ChatBot Interactions:\n",
    "\n",
    "\t1.\tLoading a Dataset and Understanding df.shape:\n",
    "\t•\tWe discussed how to load a dataset using pandas from the provided URL and explored the difference between using the df.shape attribute, which provides the number of rows and columns in a DataFrame, and the df.describe() method, which offers a summary of numerical columns.\n",
    "\t2.\tAttributes vs. Methods:\n",
    "\t•\tI explained the difference between an attribute (e.g., df.shape) and a method (e.g., df.describe()):\n",
    "\t•\tAn attribute is a characteristic that provides stored information without needing parentheses.\n",
    "\t•\tA method is a function associated with an object that performs operations and requires parentheses when invoked.\n",
    "\t3.\tUnderstanding df.describe() Output:\n",
    "\t•\tWe went over the summary statistics provided by df.describe(), including definitions for:\n",
    "\t•\tcount: Number of non-missing values.\n",
    "\t•\tmean: The average of the values.\n",
    "\t•\tstd: Standard deviation, indicating variability in the data.\n",
    "\t•\tmin/max: The minimum and maximum values.\n",
    "\t•\tpercentiles: The 25th, 50th (median), and 75th percentiles that describe the distribution of the data.\n",
    "\t•\tThese statistics help summarize the key aspects of the numeric data in a DataFrame.\n",
    "\t4.\tHandling Non-numeric and Missing Data:\n",
    "\t•\tWe discussed how df.describe() only includes numeric columns by default, and how it handles missing values in numeric columns by reducing the “count” in its summary output.\n",
    "\n",
    "This summary encapsulates the main points of our discussion. You can use this as part of your homework submission. Let me know if you need any more details!\n",
    "\n",
    "link:https://chatgpt.com/share/cd8236c1-1c16-4f63-b47a-97c33731d99c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013ed822",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q7\n",
    "#1)Example: If I have a dataset of customer information (e.g., names, emails, and phone numbers), but some rows have missing values in the email or phone number column, I may want to remove only the rows with missing data to preserve the columns that are still relevant. This way, I can retain rows where at least one of the two columns (email or phone number) is complete.\n",
    "\n",
    "df.dropna(axis=0, inplace=True)  # Dropping rows with missing data\n",
    "\n",
    "#2)Example:If I am analyzing customer purchase behavior and the column middle_name has 90% missing values and is not relevant to my analysis, I can delete it entirely to avoid losing valuable rows for the rest of the dataset.\n",
    "\n",
    "del df['middle_name']  # Removing a column with excessive missing values\n",
    "\n",
    "#3) Applying del df['col'] before df.dropna() is important because columns with many missing values can skew the results of df.dropna(). If I attempt to drop rows first, I might lose more data than necessary. By removing columns with excessive missing values first, I ensure that only the necessary rows are dropped, preserving the maximum amount of useful information from the other columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ace40efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before cleaning:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 391 entries, 0 to 390\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   row_n        391 non-null    int64 \n",
      " 1   id           390 non-null    object\n",
      " 2   name         391 non-null    object\n",
      " 3   gender       391 non-null    object\n",
      " 4   species      391 non-null    object\n",
      " 5   birthday     391 non-null    object\n",
      " 6   personality  391 non-null    object\n",
      " 7   song         380 non-null    object\n",
      " 8   phrase       391 non-null    object\n",
      " 9   full_id      391 non-null    object\n",
      " 10  url          391 non-null    object\n",
      "dtypes: int64(1), object(10)\n",
      "memory usage: 33.7+ KB\n",
      "None\n",
      "row_n           0\n",
      "id              1\n",
      "name            0\n",
      "gender          0\n",
      "species         0\n",
      "birthday        0\n",
      "personality     0\n",
      "song           11\n",
      "phrase          0\n",
      "full_id         0\n",
      "url             0\n",
      "dtype: int64\n",
      "\n",
      "After cleaning:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 379 entries, 0 to 390\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   row_n        379 non-null    int64 \n",
      " 1   id           379 non-null    object\n",
      " 2   name         379 non-null    object\n",
      " 3   gender       379 non-null    object\n",
      " 4   species      379 non-null    object\n",
      " 5   birthday     379 non-null    object\n",
      " 6   personality  379 non-null    object\n",
      " 7   song         379 non-null    object\n",
      " 8   phrase       379 non-null    object\n",
      " 9   full_id      379 non-null    object\n",
      " 10  url          379 non-null    object\n",
      "dtypes: int64(1), object(10)\n",
      "memory usage: 35.5+ KB\n",
      "None\n",
      "row_n          0\n",
      "id             0\n",
      "name           0\n",
      "gender         0\n",
      "species        0\n",
      "birthday       0\n",
      "personality    0\n",
      "song           0\n",
      "phrase         0\n",
      "full_id        0\n",
      "url            0\n",
      "dtype: int64\n",
      "\n",
      "Original number of rows: 391\n",
      "Number of rows after cleaning: 379\n",
      "Number of rows removed: 12\n"
     ]
    }
   ],
   "source": [
    "#4)\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Step 2: Inspect missing data\n",
    "print(\"Before cleaning:\")\n",
    "print(df.info())\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Step 3: Remove missing data\n",
    "# We will remove rows with missing values for simplicity\n",
    "df_cleaned = df.dropna()\n",
    "\n",
    "# Step 4: Generate before and after reports\n",
    "print(\"\\nAfter cleaning:\")\n",
    "print(df_cleaned.info())\n",
    "print(df_cleaned.isnull().sum())\n",
    "\n",
    "# Optionally, if we want to see how many rows were removed\n",
    "print(f\"\\nOriginal number of rows: {df.shape[0]}\")\n",
    "print(f\"Number of rows after cleaning: {df_cleaned.shape[0]}\")\n",
    "print(f\"Number of rows removed: {df.shape[0] - df_cleaned.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f0310a",
   "metadata": {},
   "source": [
    "Justification:\n",
    "Loading and Inspecting Data:\n",
    "\n",
    "Loading the data allows us to understand its structure and content.\n",
    "Inspecting missing values helps determine how critical the missing data is. If only a few values are missing, it might be acceptable to drop those rows.\n",
    "Removing Missing Data:\n",
    "\n",
    "Using df.dropna() is a straightforward method when missing data is scattered across rows or if the missing values are not critical. It removes any row with at least one missing value.\n",
    "Alternatively, if missing values are predominantly in specific columns and those columns are not essential for analysis, dropping those columns might be more appropriate.\n",
    "Before and After Report:\n",
    "\n",
    "The .info() method provides insights into the number of non-null values in each column.\n",
    "The .isnull().sum() method helps quantify missing values before and after cleaning.\n",
    "Reporting the number of rows before and after gives a clear picture of how much data was removed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78406ec",
   "metadata": {},
   "source": [
    "Here’s a summary of our interactions:\n",
    "\n",
    "Topic: Missing Data and Data Cleaning Techniques\n",
    "Initial Question: You asked about when to use df.dropna() versus del df['col'] in data cleaning, providing examples of scenarios where one might be preferred over the other. You also asked why it could be important to use del df['col'] before df.dropna() when used together.\n",
    "\n",
    "My Response:\n",
    "\n",
    "Use case for df.dropna(): Preferred when you want to drop rows with missing values in any column, retaining columns with complete data.\n",
    "Use case for del df['col']: Preferred when a single column has too many missing values, and the column isn't important to the analysis.\n",
    "Why use del df['col'] first: Removing columns with excessive missing data can prevent dropping too many rows unnecessarily, thus preserving more useful data.\n",
    "I provided an example approach where del df['col'] is used first to remove a column, followed by df.dropna() to clean remaining missing values, showing both before-and-after reports.\n",
    "Dataset Request:\n",
    "\n",
    "You provided a URL for a dataset (villagers.csv), asking for an analysis to remove missing data.\n",
    "Technical Limitation:\n",
    "\n",
    "I attempted to load the dataset but encountered a technical issue with the data tool. I provided a code snippet for you to load the dataset locally and proceed with the analysis.\n",
    "This summary captures our key exchanges for your homework submission. Let me know if you'd like any further clarification!\n",
    "\n",
    "Link:https://chatgpt.com/share/8e19c319-5207-48f9-ac59-e6a286af3b5d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a556de8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
      "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
      "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
      "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
      "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
      "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
      "\n",
      "     who  adult_male deck  embark_town alive  alone  \n",
      "0    man        True  NaN  Southampton    no  False  \n",
      "1  woman       False    C    Cherbourg   yes  False  \n",
      "2  woman       False  NaN  Southampton   yes   True  \n",
      "3  woman       False    C  Southampton   yes  False  \n",
      "4    man        True  NaN  Southampton    no   True  \n",
      "        count       mean        std  min       25%      50%   75%       max\n",
      "class                                                                      \n",
      "First   216.0  84.154687  78.380373  0.0  30.92395  60.2875  93.5  512.3292\n",
      "Second  184.0  20.662183  13.417399  0.0  13.00000  14.2500  26.0   73.5000\n",
      "Third   491.0  13.675550  11.778142  0.0   7.75000   8.0500  15.5   69.5500\n"
     ]
    }
   ],
   "source": [
    "#Q8 \n",
    "#1)\n",
    "import pandas as pd\n",
    "\n",
    "# Load Titanic dataset\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv')\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fdb43f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        count       mean        std  min       25%      50%   75%       max\n",
      "class                                                                      \n",
      "First   216.0  84.154687  78.380373  0.0  30.92395  60.2875  93.5  512.3292\n",
      "Second  184.0  20.662183  13.417399  0.0  13.00000  14.2500  26.0   73.5000\n",
      "Third   491.0  13.675550  11.778142  0.0   7.75000   8.0500  15.5   69.5500\n"
     ]
    }
   ],
   "source": [
    "#Example: I want to understand how the fare distribution differs by passenger class. \n",
    "# Group by 'class' and get descriptive statistics for 'fare'\n",
    "result = df.groupby('class')['fare'].describe()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e442c2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2)\n",
    "#df.describe()\n",
    "          year       species         count    location\n",
    "count  1000.0        1000         950.0       1000\n",
    "mean   2020.0        NaN           50.0        NaN\n",
    "std       2.0        NaN           25.0        NaN\n",
    "min    2018.0        NaN            1.0        NaN\n",
    "25%    2019.0        NaN           30.0        NaN\n",
    "50%    2020.0        NaN           50.0        NaN\n",
    "75%    2021.0        NaN           70.0        NaN\n",
    "max    2022.0        NaN          100.0        NaN\n",
    "#count for species and location might show fewer non-null entries due to missing values.\n",
    "\n",
    "#df.groupby(\"species\")[\"count\"].describe()\n",
    "         count       mean        std   min   25%   50%   75%   max\n",
    "species                                                              \n",
    "A        300.0      45.0       15.0    5.0   30.0  45.0  60.0   80.0\n",
    "B        350.0      55.0       20.0    1.0   35.0  55.0  70.0  100.0\n",
    "C        250.0      60.0       25.0   10.0   40.0  60.0  80.0  90.0\n",
    "# the count represents the number of non-null count values for each species. The mean, std, min, 25%, 50%, 75%, and max provide statistics specific to each species group."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da38015",
   "metadata": {},
   "source": [
    "Summary of Differences\n",
    "\n",
    "1.Global vs. Group-Level Analysis:\n",
    "\t•\tdf.describe(): Gives an overview of missing data across the entire DataFrame. For columns with missing values, the count will be less than the total number of rows.\n",
    "\t•\tdf.groupby(\"species\")[\"count\"].describe(): Shows missing data within each group. The count reflects non-null entries specific to each group, revealing how missing data is distributed among different categories.\n",
    "2.Impact of Missing Data:\n",
    "\t•\tdf.describe(): The count provides a global picture of completeness. If there are many missing values, the count will be lower, affecting overall statistics.\n",
    "\t•\tdf.groupby(\"species\")[\"count\"].describe(): Provides group-specific insights. Missing values are assessed within each group, so counts and statistics vary by group.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc41b631",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3)\n",
    "1.forget to import panadas\n",
    "#error: NameError: name 'pd' is not defined\n",
    "#chatgpt troubleshooting:\n",
    "import pandas as pd\n",
    "#Google Search:Searching “NameError: name ‘pd’ is not defined” would similarly lead me to a solution that involves ensuring pandas is imported.\n",
    "\n",
    "2.Mistyping the Filename\n",
    "#error:FileNotFoundError: [Errno 2] No such file or directory: 'titanics.csv'\n",
    "#chatgpt troubleshooting:suggest checking the filename or path. \n",
    "df = pd.read_csv('titanic.csv')  # Correct filename\n",
    "#geogle search: Searching “FileNotFoundError: [Errno 2] No such file or directory: ‘titanics.csv’” would lead to similar advice, usually suggesting checking the file path or filename.\n",
    "\n",
    "3.Using a DataFrame Before Assignment\n",
    "#error: NameError: name 'DF' is not defined\n",
    "#ChatGPT troubleshooting: indicates that DF is not defined and should be df. The solution would involve ensuring correct variable names.\n",
    "#Google Search:Searching “NameError: name ‘DF’ is not defined” would also direct you to check for variable name mismatches.\n",
    "\n",
    "4.Forgetting a Parenthesis\n",
    "#error: SyntaxError: unexpected EOF while parsing\n",
    "#ChatGPT Troubleshooting:highlight the missing parenthesis and suggest the correct syntax.\n",
    "pd.read_csv('url')  # Correct code\n",
    "#Google Search:Searching “SyntaxError: unexpected EOF while parsing” would similarly suggest checking for missing parentheses.\n",
    "\n",
    "5.Mistyping a Chained Function\n",
    "#error: AttributeError: 'DataFrame' object has no attribute 'group_by'/AttributeError: 'DataFrame' object has no attribute 'describle'\n",
    "#ChatGPT Troubleshooting:point out the incorrect method names and suggest the correct ones.\n",
    "df.groupby('col1')['col2'].describe()  # Correct method\n",
    "#Geogle search: Searching “AttributeError: ‘DataFrame’ object has no attribute ‘group_by’” would provide similar advice, with examples of correct method usage.\n",
    "\n",
    "6.Using a Column Name Not in Data\n",
    "#error: KeyError: 'Sex'\n",
    "#ChatGPT Troubleshooting:suggest verifying the column names in the DataFrame.\n",
    "df.columns  # To check available columns\n",
    "#Google Search:Searching “KeyError: ‘Sex’” would lead to checking the column names and ensuring correct spelling.\n",
    "\n",
    "7. Forgetting Quotes Around Column Names\n",
    "#error: NameError: name 'sex' is not defined\n",
    "        KeyError: 'age'\n",
    "#ChatGPT Troubleshooting: suggest using quotes around column names.\n",
    "#Google Search:Searching “NameError: name ‘sex’ is not defined” or “KeyError: ‘age’” would provide similar guidance about using string literals for column names."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6db553",
   "metadata": {},
   "source": [
    "In general:\n",
    "ChatGPT can offer targeted advice and explanations tailored to specific code issues, which might be faster for understanding and fixing errors directly within a coding context. Google is useful for broader searches and provides a variety of resources and examples, which might be better for learning and understanding concepts in depth."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745415f2",
   "metadata": {},
   "source": [
    "Summary of Exchanges\n",
    "1. Understanding df.groupby(\"col1\")[\"col2\"].describe()\n",
    "•\tConcept: The method df.groupby(\"col1\")[\"col2\"].describe() is used to compute descriptive statistics for a column (col2) within each group defined by another column (col1). It provides count, mean, standard deviation, min, quartiles, and max, specific to each group.\n",
    "•\tComparison:\n",
    "    •\tdf.describe(): Provides global descriptive statistics for each column across the entire DataFrame, with counts showing the number of non-null entries.\n",
    "\t•\tdf.groupby(\"col1\")[\"col2\"].describe(): Provides descriptive statistics within each group defined by col1, with counts showing non-null entries specific to each group.\n",
    "2. Demonstration with Titanic Dataset\n",
    "3. Error Handling and Troubleshooting\n",
    "•\tErrors Introduced:\n",
    "•\tForgetting Import: NameError: name 'pd' is not defined\n",
    "•\tMistyping Filename: FileNotFoundError: [Errno 2] No such file or directory: 'titanics.csv'\n",
    "•\tUsing Unassigned Variable: NameError: name 'DF' is not defined\n",
    "•\tMissing Parenthesis: SyntaxError: unexpected EOF while parsing\n",
    "•\tMistyped Function Names: AttributeError: 'DataFrame' object has no attribute 'group_by' and AttributeError: 'DataFrame' object has no attribute 'describle'\n",
    "•\tInvalid Column Names: KeyError: 'Sex'\n",
    "•\tOmitting Quotes: NameError: name 'sex' is not defined and KeyError: 'age'\n",
    "•\tTroubleshooting:\n",
    "•\tChatGPT: Provides direct guidance and explanations for fixing errors.\n",
    "•\tGoogle Search: Offers a variety of examples and solutions for error resolution.\n",
    "4. Analyzing Missing Data\n",
    "•\tDifference in Count Values:\n",
    "•\tdf.describe(): Shows count of non-null entries across the entire DataFrame, giving a global view of data completeness.\n",
    "•\tdf.groupby(\"col1\")[\"col2\"].describe(): Shows count of non-null entries within each group, giving a granular view of data completeness by category.\n",
    "•\tHandling Missing Data:\n",
    "•\tRemoving Rows: df.dropna() to exclude incomplete rows.\n",
    "•\tRemoving Columns: df.drop(columns=['col']) to exclude columns with too many missing values.\n",
    "•\tImputation: Filling missing values using df.fillna(value={'col': 0}).\n",
    "5. Example with mas.csv Dataset\n",
    "Feel free to adjust any specific details as needed for your homework assignment.\n",
    "link:https://chatgpt.com/share/635f4c76-d37c-4cd3-bdf1-0d5a200542ea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a5023e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q9 \n",
    "#Mostly"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
